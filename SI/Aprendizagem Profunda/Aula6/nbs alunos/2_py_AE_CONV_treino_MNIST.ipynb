{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Autoencoder simples com convoluções utilizando o MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image_info](https://www.researchgate.net/publication/353450665/figure/fig3/AS:1049661439750148@1627270197721/Autoencoder-Framework.png)\n",
    "\n",
    "![image info](https://miro.medium.com/max/875/1*0pP2fZwuT0B9ndRF4FPEtw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch mlp for binary classification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import image\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import Sequential\n",
    "from torch.nn import Linear\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import BatchNorm2d\n",
    "from torch.nn import ConvTranspose2d\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Softmax, Tanh\n",
    "from torch.nn import Module\n",
    "from torch.nn import MSELoss, BCELoss\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "from torch.nn.init import xavier_uniform_\n",
    "from torch.optim import SGD, Adam \n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "    \n",
    "from torchvision.transforms import Compose\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "#pip install torchinfo\n",
    "from torchinfo import summary\n",
    "from livelossplot import PlotLosses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\n",
    "\n",
    "#path para guardar o dataset\n",
    "PATH = './'\n",
    "PATH_TRAIN = './mnist_train.csv'\n",
    "PATH_TEST = './mnist_test.csv'\n",
    "\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#device management \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)\n",
    "\n",
    "device = get_default_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Preparar os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#buscar o dataset utilizando os CSVs e uma classe para o dataset\n",
    "\n",
    "# definição classe para o dataset\n",
    "class CSVDataset(Dataset):\n",
    "    # ler o dataset\n",
    "    def __init__(self, path_train, path_test):\n",
    "        df_train = pd.read_csv(path_train,header = 0)\n",
    "        df_test = pd.read_csv(path_test,header = 0)\n",
    "        # separar os inputs e os outputs\n",
    "        self.x_train = df_train.values[:, 1:]\n",
    "        xmax, xmin = self.x_train.max(), self.x_train.min()\n",
    "        self.x_train = (self.x_train - xmin)/(xmax - xmin)\n",
    "        self.y_train = df_train.values[:, 0]\n",
    "        self.x_test = df_test.values[:, 1:]\n",
    "        xmax, xmin = self.x_test.max(), self.x_test.min()\n",
    "        self.x_test = (self.x_test - xmin)/(xmax - xmin)\n",
    "        self.y_test = df_test.values[:, 0]\n",
    "        # garantir que os inputs e labels sejam floats\n",
    "        self.x_train = self.x_train.astype('float32')\n",
    "        self.x_test = self.x_test.astype('float32')\n",
    "        self.y_train = self.y_train.astype('long')\n",
    "        self.y_test = self.y_test.astype('long')\n",
    "        \n",
    "    # numero de casos de treino no dataset\n",
    "    def __len_train__(self):\n",
    "        return len(self.x_train)\n",
    "     # numero de casos de teste no dataset\n",
    "    def __len_test__(self):\n",
    "        return len(self.x_test)\n",
    "    \n",
    "    # retornar um caso\n",
    "    def __getitem_train__(self, idx):\n",
    "        return [self.x_train[idx], self.y_train[idx]]\n",
    "     # retornar um caso\n",
    "    def __getitem_test__(self, idx):\n",
    "        return [self.x_test[idx], self.y_test[idx]]\n",
    "    \n",
    "    # retornar indeces para casos de treino de de teste em formato flat (vetor)\n",
    "    def get_splits(self):\n",
    "        x_train = torch.from_numpy(np.array(self.x_train))\n",
    "        y_train = torch.from_numpy(np.array(self.y_train))\n",
    "        x_test = torch.from_numpy(np.array(self.x_test))\n",
    "        y_test = torch.from_numpy(np.array(self.y_test))\n",
    "        train = torch.utils.data.TensorDataset(x_train,y_train)\n",
    "        test = torch.utils.data.TensorDataset(x_test,y_test)\n",
    "        return train, test      \n",
    "    \n",
    "# preparar o dataset\n",
    "def prepare_data_flat(path_train, path_test):\n",
    "    # criar uma instancia do dataset\n",
    "    dataset = CSVDataset(path_train, path_test)\n",
    "    # calcular split\n",
    "    train, test = dataset.get_splits()\n",
    "    # preparar data loaders\n",
    "    train_dl = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_dl = DataLoader(test, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    train_dl_all = DataLoader(train, batch_size=len(train), shuffle=False)\n",
    "    test_dl_all = DataLoader(test, batch_size=len(test), shuffle=False)\n",
    "    return train_dl, test_dl, train_dl_all, test_dl_all\n",
    "\n",
    "# preparar os dados\n",
    "train_dl, test_dl,  train_dl_all, test_dl_all = prepare_data_flat(PATH_TRAIN, PATH_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.1 Visualizar os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "0          5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "1          0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "2          4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "3          1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "4          9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...    ...   \n",
       "59995      8    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "59996      3    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "59997      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "59998      6    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "59999      8    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "       28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0          0      0      0      0      0      0      0      0  \n",
       "1          0      0      0      0      0      0      0      0  \n",
       "2          0      0      0      0      0      0      0      0  \n",
       "3          0      0      0      0      0      0      0      0  \n",
       "4          0      0      0      0      0      0      0      0  \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "59995      0      0      0      0      0      0      0      0  \n",
       "59996      0      0      0      0      0      0      0      0  \n",
       "59997      0      0      0      0      0      0      0      0  \n",
       "59998      0      0      0      0      0      0      0      0  \n",
       "59999      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[60000 rows x 785 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "def visualize_data(path):\n",
    "    # criar uma instancia do dataset\n",
    "    df = pd.read_csv(path, header=0)\n",
    "    display(df)\n",
    "\n",
    "def visualize_dataset(train_dl, test_dl):\n",
    "    print(f\"Quantidade de casos de Treino:{len(train_dl.dataset)}\") \n",
    "    print(f\"Quantidade de casos de Teste:{len(test_dl.dataset)}\")\n",
    "    x, y = next(iter(train_dl)) #fazer uma iteração nos loaders para ir buscar um batch de casos\n",
    "    print(f\"Shape tensor batch casos treino, input: {x.shape}, output: {y.shape}\")\n",
    "    x, y = next(iter(test_dl))  \n",
    "    print(f\"Shape tensor batch casos test, input: {x.shape}, output: {y.shape}\")\n",
    "    print(y)\n",
    "\n",
    "visualize_data(PATH_TRAIN)\n",
    "visualize_dataset(train_dl, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Visualização das imagens\n",
    "def visualize_mnist_images_flat(dl):\n",
    "    # get one batch of images\n",
    "    i, (inputs, targets) = next(enumerate(dl))\n",
    "    print(inputs.shape)\n",
    "    print(inputs.shape)\n",
    "    # plot some images\n",
    "    plt.figure(figsize=(8,8))\n",
    "    for i in range(25):\n",
    "        # define subplot\n",
    "        plt.subplot(5, 5, i+1)\n",
    "        plt.axis('off')\n",
    "        plt.grid(False)\n",
    "        # plot raw pixel data\n",
    "        plt.imshow(inputs[i][0], cmap='gray')\n",
    "    # show the figure\n",
    "    plt.show()\n",
    "\n",
    "visualize_mnist_images_flat(train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Definir o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models_mnist #modulo python com os modelos       \n",
    "    \n",
    "# definir a rede neuronal\n",
    "model = ...\n",
    "#visualizar a rede\n",
    "print(summary(model, input_size=(BATCH_SIZE,  1,28,28), verbose=0)) \n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Treinar o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# treino do modelo\n",
    "def train_model(h5_file,train_dl, test_dl, model, loss_function, optimizer, scheduler, epochs):\n",
    "    liveloss = PlotLosses() \n",
    "    for epoch in range(epochs):\n",
    "        logs = {} \n",
    "        model.train()\n",
    "        running_loss  = 0.0 \n",
    "        for _, (inputs, _) in enumerate(train_dl): \n",
    "            inputs = inputs.to(device)\n",
    "            outputs,_ = model(inputs)\n",
    "            loss = loss_function(outputs, inputs)\n",
    "            optimizer.zero_grad() \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        epoch_loss = running_loss / len(train_dl.dataset)\n",
    "        logs['loss'] = epoch_loss*1000\n",
    "        #Validation phase\n",
    "        model.eval()\n",
    "        running_loss  = 0.0\n",
    "        for inputs, labels in test_dl: \n",
    "            inputs = inputs.to(device)\n",
    "            outputs,_ = model(inputs)\n",
    "            loss = loss_function(outputs, inputs)\n",
    "            running_loss += loss.item() \n",
    "        epoch_loss = running_loss / len(test_dl.dataset)\n",
    "        logs['val_loss'] = epoch_loss*1000    \n",
    "        scheduler.step(epoch_loss) #callback a meio para atualizar lr\n",
    "        epoch_lr = optimizer.param_groups[0]['lr'] \n",
    "        logs['val_lr'] = epoch_lr \n",
    "        liveloss.update(logs) #para visualizarmos o processo de treino\n",
    "        liveloss.send() #para visualizarmos o processo de treino\n",
    "    torch.save(model,h5_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# treinar o modelo\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# definir o loss e a função de otimização\n",
    "loss_function = BCELoss()\n",
    "optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler=StepLR(optimizer,step_size=10,gamma=0.95)\n",
    "starttime = time.perf_counter()\n",
    "train_model(..., train_dl, test_dl, model, loss_function, optimizer, scheduler, EPOCHS)\n",
    "endtime = time.perf_counter()\n",
    "print(f\"Tempo gasto: {endtime - starttime} segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Usar o Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(input_imgs, output_imgs):\n",
    "    input_imgs=input_imgs.permute((1, 2, 0))\n",
    "    output_imgs=output_imgs.permute((1, 2, 0))\n",
    "    plt.subplots(1,2, figsize=(10, 10))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.axis('off')\n",
    "    plt.grid(b=None)\n",
    "    plt.title('Autoencoder Input')\n",
    "    plt.imshow(input_imgs, cmap='gray')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.axis('off')\n",
    "    plt.grid(b=None)\n",
    "    plt.title('Autoencoder Output')\n",
    "    plt.imshow(output_imgs, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "def test_image_reconstruction(model, test_dl):\n",
    "    for batch in test_dl:\n",
    "        img, _ = batch\n",
    "        img = img.to(device)\n",
    "        print(img.shape)\n",
    "        outputs,_ = model(img)\n",
    "        print(outputs.shape)\n",
    "        outputs = outputs.view(outputs.size(0), 1, 28, 28).cpu().data\n",
    "        print(outputs.shape)\n",
    "        inputs = img.view(outputs.size(0), 1, 28, 28).cpu().data\n",
    "        outputs = make_grid(outputs)\n",
    "        inputs = make_grid(inputs)\n",
    "        break \n",
    "    return inputs, outputs\n",
    "\n",
    "model= torch.load('AE_CONV_MNIST.pth')\n",
    "inputs, outputs = test_image_reconstruction(model, test_dl)\n",
    "visualize(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fazer uma previsão utilizando um caso\n",
    "def make_prediction(model, img_list, idx):\n",
    "    print(img_list.shape)\n",
    "    print(img_list.dtype) \n",
    "    img_list = img_list.to(device)  \n",
    "    prediction,_ = model(img_list)\n",
    "    print(prediction.shape)\n",
    "    prediction = prediction.view(prediction.size(0), 1, 28, 28).cpu().data\n",
    "    print(prediction.shape)\n",
    "    img = img_list[idx].reshape(1,28, 28).cpu()\n",
    "    plt.subplots(1,2, figsize=(10, 10))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.axis('off')\n",
    "    plt.grid(b=None)\n",
    "    plt.title('Imagem Input')\n",
    "    plt.imshow(img.permute((1, 2, 0)), cmap='gray')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.axis('off')\n",
    "    plt.grid(b=None)\n",
    "    plt.title('Imagem Output')\n",
    "    plt.imshow(prediction[idx].permute((1, 2, 0)), cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "_, (inputs, targets) = next(enumerate(test_dl))\n",
    "make_prediction(model,inputs, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
